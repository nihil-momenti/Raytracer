\section{Background}
  \subsection{Lights}
    As well as the directional and ambient light sources point light and focused
    lights were added.  Point lights are calculated similarly to directional
    lights, just instead of using their given direction the direction used is
    from the point of of intersection to the light sources location.  Focused
    lights are similar to point lights with a spread function modifier.  The
    spread function used is:
    \[ \frac{\max\left(0,\, \theta - \cos^{-1}\left( \mathbf{d} \cdot
    \mathbf{v}\right)\right)}{\theta} \]
    Where $\mathbf{d}$ is the unit direction vector that the light is aimed in,
    $\mathbf{v}$ is the unit direction vector from the light sources location to
    the point of intersection and $\theta$ is the angle of the light sources
    spread.

  \subsection{Antialiasing}
    The method of antialiasing used is just simple multisampling.  Instead of
    sampling each pixel with just a ray through the centre, each pixel is split
    up into a grid of sub-pixels.  Each of these sub-pixels are then sampled
    through their centres and the resulting values are averaged for the pixel.
    The main dis-advantage of this is the major performance hit taken, because
    of the 2d grid used for each pixel even just 2X anti-aliasing requires 4
    seperate rays per pixel, slowing the algorithm down by 4 times.  Stepping up
    to 3X anti-aliasing increases this to 9 seperate rays per pixel taking 9
    times as long, or 2.25 times as long as 2X.  To get a really good picture
    you have to sample at at least 4X or 5X, which means you must generate much
    smaller pictures to have them comparable generation times.

    To try and offset this drastic performance hit a simple optimisation was
    performed, the algorithm was split into a two pass algorithm.  First pass
    each pixels colour is generated with just a single ray.  Next each pixel is
    compared to its neighbours and if the colour differs then antialiasing is
    applied to that pixel.  This works very well for images with a lot of single
    shade objects.  As textures and more complex reflections and lighting are
    applied the performance gain decreases, and infact if the image were complex
    enough to require antialiasing to be applied to every pixel this would slow
    it down.  However the potential time savings per pixel are much greater than
    the potential slowdowns (at least with high levels of antialiasing) so even
    with very busy images the few pixels that can be ignored should more than
    makeup for any performance losses.

  \subsection{Transformations}
    There were only two transformations implemented, translation and rotation.
    Shearing and scaling can be easily implemented ontop of the transformation
    framework given and should take less than 40 lines of code each.

    \subsubsection{Translation}
      Instead of using the matrix form for translation it was decided that it
      was easier just using a vector by which to translate the shape.  When any
      of the shapes methods are called with a point that point has the
      translation vector added on to it.  When any of the shapes methods return
      a point the translation vector is taken off it.

    \subsubsection{Rotation}
      The first implementation of rotation was attempted with matrix
      multiplication.  This however failed, as far as could be seen the code
      matched the correct maths but it still refused to work.  Instead rotation
      has been implemented by converting any points or vectors into a
      cylindrical polar space with z axis parallel to the axis of rotation, the
      rotation is then applied by adding the given angle to the point/vector and
      finally the point/vector is converted back to the world co-ordinate
      system.

      To generate the cylindrical polar space the axis along which the rotation
      should rotate is given as a unit vector. This is chosen to represent the
      $\mathbf{z}$ vector in the standard cylindrical polar co-ordinate system,
      and is named $\mathbf{v}$.
      Next a random vector is generated and checked to ensure it is not parallel
      to the given axis.  This is then orthognalised to the given axis and
      converted to a unit vector to use as one axis.  Finally the cross-product
      of these two axes is found and is used as the third axis.

      The randomly generated axis from this procedure is chosen to represent the
      $\mathbf{y}$ axis from conventional cylindrical polar co-ordinate space
      and named $\mathbf{w}$, while the cross product is chosen to represent
      $\mathbf{x}$ and is named $\mathbf{u}$.

      This allows us to convert a vector or point $\mathbf{p} =
      \left(x,\,y,\,z\right)$ into its transformed equivalent $\mathbf{p}' =
      \left(x',\,y',\,z'\right)$ as follows.

      \noindent First convert from $\left(x,\,y,\,z\right)$ into $\left(u,\,w,\,v\right)$:
      \[ u = \mathbf{p} \cdot \mathbf{u} \qquad w = \mathbf{p} \cdot \mathbf{w}
         \qquad v = \mathbf{p} \cdot \mathbf{v} \]
      Next convert into $\left(\rho,\,\theta,\,z\right)$ and apply the rotation
      (of magnitude $\theta_r$):
      \[ \rho = \sqrt{u ^2 + w ^2} \qquad \theta =
      \textrm{atan2}\left(w,\,u\right) + \theta_r \qquad z = v \]
      Then convert back to $\left(u,\,w,\,v\right)$:
      \[ u = \rho\cos\theta \qquad w = \rho\sin\theta \qquad v = z \]
      And finally back to $\left(x,\,y,\,z\right)$:
      \[ \mathbf{p}' = u \mathbf{u} + w \mathbf{w} + v \mathbf{v} \]

    \subsection{Constructive Solid Geometry (CSG)}
      To assist with creating CSG objects the intersection methods of the
      shapes were changed to return a tuple with values of where the ray enters
      the object and where it exits the object.  This allows very simple
      calculations of intersections, the entry is the maximum entry point and
      the exit is the minimum exit point.  If the entry point is after the exit
      point then the ray doesn't intersect the object.  The problem with this
      system is that when unions and subtraction were attempted to be
      implemented they couldn't work with the data structure.


